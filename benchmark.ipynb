{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\bf contact-high-school \t&23.908 \t&2.327 \t&55.633 \t&0.504 \t&0.582 \t&0.750\\\\\n",
      "HyperDK00 \t&272.161 + 0.260 \t&3.089 + 0.003 \t&840.796 + 0.714 \t&0.999 + 0.000 \t&0.000 + 0.000 \t&0.324 + 0.000\\\\\n",
      "HyperDK11 \t&142.573 + 0.142 \t&2.178 + 0.000 \t&310.567 + 0.270 \t&0.861 + 0.001 \t&0.016 + 0.001 \t&0.459 + 0.000\\\\\n",
      "Hyperlap \t&23.938 + 0.040 \t&2.327 + 0.000 \t&55.701 + 0.093 \t&0.341 + 0.004 \t&0.394 + 0.006 \t&0.622 + 0.004\\\\\n",
      "Hyperlap+ \t&23.908 + 0.000 \t&2.327 + 0.000 \t&55.633 + 0.000 \t&0.632 + 0.005 \t&0.742 + 0.001 \t&0.747 + 0.001\\\\\n",
      "TheRA \t&23.908 + 0.000 \t&2.609 + 0.000 \t&62.382 + 0.000 \t&0.354 + 0.000 \t&0.405 + 0.000 \t&0.831 + 0.000\\\\\n",
      "HyperPLR \t&24.055 + 0.000 \t&2.703 + 0.003 \t&65.011 + 0.073 \t&0.471 + 0.000 \t&0.556 + 0.000 \t&0.649 + 0.003\\\\\n",
      "\\bf contact-primary-school \t&52.496 \t&2.419 \t&126.979 \t&0.526 \t&0.284 \t&0.634\\\\\n",
      "HyperDK00 \t&229.896 + 0.490 \t&3.129 + 0.003 \t&719.429 + 0.927 \t&1.000 + 0.000 \t&0.000 + 0.000 \t&0.319 + 0.000\\\\\n",
      "HyperDK11 \t&143.343 + 0.110 \t&2.285 + 0.000 \t&327.516 + 0.218 \t&0.924 + 0.001 \t&0.010 + 0.000 \t&0.437 + 0.000\\\\\n",
      "Hyperlap \t&52.496 + 0.000 \t&2.419 + 0.000 \t&126.979 + 0.000 \t&0.496 + 0.001 \t&0.281 + 0.003 \t&0.620 + 0.002\\\\\n",
      "Hyperlap+ \t&52.496 + 0.000 \t&2.419 + 0.000 \t&126.979 + 0.000 \t&0.655 + 0.023 \t&0.496 + 0.001 \t&0.640 + 0.026\\\\\n",
      "TheRA \t&52.496 + 0.000 \t&2.767 + 0.000 \t&145.252 + 0.000 \t&0.446 + 0.000 \t&0.150 + 0.000 \t&0.758 + 0.000\\\\\n",
      "HyperPLR \t&52.714 + 0.000 \t&2.648 + 0.004 \t&139.593 + 0.217 \t&0.491 + 0.000 \t&0.281 + 0.002 \t&0.600 + 0.002\\\\\n",
      "\\bf email-Enron \t&10.573 \t&3.009 \t&31.818 \t&0.593 \t&0.348 \t&0.656\\\\\n",
      "HyperDK00 \t&52.045 + 0.282 \t&3.188 + 0.012 \t&165.933 + 0.420 \t&0.958 + 0.002 \t&0.007 + 0.000 \t&0.322 + 0.001\\\\\n",
      "HyperDK11 \t&39.596 + 0.091 \t&2.885 + 0.004 \t&114.252 + 0.220 \t&0.796 + 0.004 \t&0.040 + 0.001 \t&0.355 + 0.001\\\\\n",
      "Hyperlap \t&10.232 + 0.039 \t&3.131 + 0.000 \t&32.034 + 0.123 \t&0.646 + 0.009 \t&0.275 + 0.046 \t&0.576 + 0.011\\\\\n",
      "Hyperlap+ \t&10.203 + 0.000 \t&3.131 + 0.000 \t&31.944 + 0.000 \t&0.841 + 0.013 \t&0.582 + 0.008 \t&0.738 + 0.002\\\\\n",
      "TheRA \t&10.203 + 0.000 \t&3.386 + 0.000 \t&34.545 + 0.000 \t&0.674 + 0.000 \t&0.166 + 0.000 \t&0.736 + 0.000\\\\\n",
      "HyperPLR \t&10.723 + 0.000 \t&3.244 + 0.035 \t&34.782 + 0.378 \t&0.593 + 0.001 \t&0.351 + 0.003 \t&0.569 + 0.002\\\\\n",
      "\\bf email-Eu \t&25.077 \t&3.426 \t&85.909 \t&0.492 \t&0.373 \t&0.681\\\\\n",
      "HyperDK00 \t&156.130 + 0.144 \t&3.125 + 0.002 \t&487.965 + 0.103 \t&0.723 + 0.001 \t&0.015 + 0.000 \t&0.327 + 0.000\\\\\n",
      "HyperDK11 \t&114.040 + 0.080 \t&2.887 + 0.001 \t&329.223 + 0.165 \t&0.788 + 0.003 \t&0.035 + 0.000 \t&0.353 + 0.000\\\\\n",
      "Hyperlap \t&25.778 + 0.124 \t&3.621 + 0.000 \t&93.338 + 0.450 \t&0.623 + 0.002 \t&0.280 + 0.008 \t&0.571 + 0.004\\\\\n",
      "Hyperlap+ \t&25.860 + 0.124 \t&3.621 + 0.000 \t&93.633 + 0.450 \t&0.785 + 0.004 \t&0.745 + 0.001 \t&0.751 + 0.003\\\\\n",
      "TheRA \t&24.868 + 0.000 \t&4.696 + 0.000 \t&116.792 + 0.000 \t&0.837 + 0.000 \t&0.099 + 0.000 \t&0.793 + 0.000\\\\\n",
      "HyperPLR \t&29.081 + 0.051 \t&3.135 + 0.014 \t&91.155 + 0.540 \t&0.446 + 0.003 \t&0.319 + 0.001 \t&0.493 + 0.005\\\\\n",
      "\\bf NDC-classes \t&0.937 \t&5.922 \t&5.550 \t&0.611 \t&0.613 \t&0.742\\\\\n",
      "HyperDK00 \t&36.112 + 0.054 \t&3.583 + 0.004 \t&129.392 + 0.051 \t&0.311 + 0.001 \t&0.038 + 0.001 \t&0.303 + 0.001\\\\\n",
      "HyperDK11 \t&31.083 + 0.056 \t&3.594 + 0.003 \t&111.711 + 0.139 \t&0.754 + 0.006 \t&0.058 + 0.001 \t&0.296 + 0.000\\\\\n",
      "Hyperlap \t&1.089 + 0.015 \t&6.166 + 0.000 \t&6.718 + 0.094 \t&0.672 + 0.010 \t&0.456 + 0.019 \t&0.575 + 0.021\\\\\n",
      "Hyperlap+ \t&1.098 + 0.008 \t&6.166 + 0.000 \t&6.767 + 0.051 \t&0.750 + 0.005 \t&0.793 + 0.051 \t&0.836 + 0.029\\\\\n",
      "TheRA \t&0.999 + 0.000 \t&6.282 + 0.000 \t&6.277 + 0.000 \t&0.793 + 0.000 \t&0.520 + 0.000 \t&0.892 + 0.000\\\\\n",
      "HyperPLR \t&1.210 + 0.015 \t&5.501 + 0.078 \t&6.655 + 0.167 \t&0.791 + 0.010 \t&0.623 + 0.005 \t&0.733 + 0.004\\\\\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "from math import sqrt\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import networkx as nx\n",
    "import community\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def hypergraph_metrics(hg):\n",
    "    # original hypergraph\n",
    "    num_edges = len(hg)\n",
    "    nodes = set()\n",
    "    node_degrees = {}\n",
    "    for edge in hg:\n",
    "        for node in edge:\n",
    "            nodes.add(node)\n",
    "            node_degrees[node] = node_degrees.get(node, 0) + 1\n",
    "    num_nodes = len(nodes)\n",
    "    \n",
    "    # density\n",
    "    density = num_edges / num_nodes\n",
    "\n",
    "    # Average size\n",
    "    avg_size = sum(len(edge) for edge in hg) / num_edges\n",
    "\n",
    "    # Average degree\n",
    "    avg_degree = sum(node_degrees.values()) / num_nodes\n",
    "\n",
    "\n",
    "    # projected graph\n",
    "    G = nx.Graph()\n",
    "    # Add all nodes from the hypergraph\n",
    "    nodes = set(node for edge in hg for node in edge)\n",
    "    G.add_nodes_from(nodes)\n",
    "    # For each hyperedge, create a clique\n",
    "    for edge in hg:\n",
    "        # Add edges between all pairs of nodes in the hyperedge\n",
    "        G.add_edges_from(itertools.combinations(edge, 2))\n",
    "    \n",
    "    part_G = community.best_partition(G)\n",
    "    mod_G = community.modularity(part_G, G)\n",
    "\n",
    "\n",
    "    # bipartite graph\n",
    "    B = nx.Graph()\n",
    "    # Add nodes for the original vertices (left set)\n",
    "    left_nodes = set(node for edge in hg for node in edge)\n",
    "    B.add_nodes_from(left_nodes, bipartite=0)\n",
    "    # Add nodes for the hyperedges (right set)\n",
    "    right_nodes = [f'e{i}' for i in range(len(hg))]\n",
    "    B.add_nodes_from(right_nodes, bipartite=1)\n",
    "    # Add edges between vertices and their corresponding hyperedges\n",
    "    for i, edge in enumerate(hg):\n",
    "        for node in edge:\n",
    "            B.add_edge(node, f'e{i}')\n",
    "\n",
    "\n",
    "    part_B = community.best_partition(B)\n",
    "    mod_B = community.modularity(part_B, B)\n",
    "\n",
    "    return {\n",
    "        \"density\": density,\n",
    "        \"average_size\": avg_size,\n",
    "        \"average_degree\": avg_degree,\n",
    "        \"coefficient\": nx.average_clustering(G),\n",
    "        \"G_modularity\": mod_G,\n",
    "        \"B_modularity\": mod_B\n",
    "    }\n",
    "\n",
    "def load_hypergraph(path):\n",
    "    with open(path, 'r') as f:\n",
    "        hg = f.readlines()\n",
    "    hg = [list(map(int, e.split())) for e in hg]\n",
    "    return hg\n",
    "\n",
    "def average_and_std_dicts(dict_list):\n",
    "    if not dict_list:\n",
    "        return {}\n",
    "\n",
    "    # Initialize the result dictionary\n",
    "    result = {}\n",
    "    \n",
    "    # Collect all values for each key\n",
    "    all_values = {}\n",
    "    for d in dict_list:\n",
    "        for key, value in d.items():\n",
    "            if key not in all_values:\n",
    "                all_values[key] = []\n",
    "            all_values[key].append(value)\n",
    "    \n",
    "    # Calculate mean and standard deviation for each key\n",
    "    for key, values in all_values.items():\n",
    "        mean = statistics.mean(values)\n",
    "        std = statistics.stdev(values) if len(values) > 1 else 0\n",
    "        result[key] = {\"mean\": mean, \"std\": std}\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "metric_baseline = pickle.load(open('./metric_baseline.pkl', 'rb'))\n",
    "# Example usage\n",
    "# dict_list = [{'a': 1, 'b': 2, 'c': 3}, {'a': 3, 'b': 5, 'c': 2}, {'a': 2, 'b': 3, 'c': 1}]\n",
    "\n",
    "graphs = ['contact-high-school', 'contact-primary-school', 'email-Enron', 'email-Eu', 'NDC-classes']\n",
    "models = ['HyperDK00','HyperDK11', 'Hyperlap', 'Hyperlap+', 'TheRA', 'HyperPLR']\n",
    "\n",
    "for graph in graphs:\n",
    "    metric_data = hypergraph_metrics(load_hypergraph(f'./data/{graph}/unique.txt'))\n",
    "    print(f'\\\\bf {graph} \\t&{metric_data[\"density\"]:.3f} \\t&{metric_data[\"average_size\"]:.3f} \\t&{metric_data[\"average_degree\"]:.3f} \\t&{metric_data[\"coefficient\"]:.3f} \\t&{metric_data[\"G_modularity\"]:.3f} \\t&{metric_data[\"B_modularity\"]:.3f}\\\\\\\\')\n",
    "    for model in models:\n",
    "        result = average_and_std_dicts(metric_baseline[(graph, model)])\n",
    "        # print(f\"{model} \\t&{result['density']['mean']:.3f}\\t&{result['average_size']['mean']:.3f}\\t&{result['average_degree']['mean']:.3f}\\t&{result['coefficient']['mean']:.3f}\\t&{result['G_modularity']['mean']:.3f}\\t&{result['B_modularity']['mean']:.3f}\\\\\\\\\")\n",
    "        print(f\"{model} \\t&{result['density']['mean']:.3f} + {result['density']['std']:.3f} \\t&{result['average_size']['mean']:.3f} + {result['average_size']['std']:.3f} \\t&{result['average_degree']['mean']:.3f} + {result['average_degree']['std']:.3f} \\t&{result['coefficient']['mean']:.3f} + {result['coefficient']['std']:.3f} \\t&{result['G_modularity']['mean']:.3f} + {result['G_modularity']['std']:.3f} \\t&{result['B_modularity']['mean']:.3f} + {result['B_modularity']['std']:.3f}\\\\\\\\\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hygen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
